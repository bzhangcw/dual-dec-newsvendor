% modified: Chuwen <chuwzhang@gmail.com>
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*,table}{xcolor}
%
\documentclass[
  a4paper,
,tablecaptionabove
]{scrartcl}
\usepackage{lmodern}
\usepackage{setspace}
\setstretch{1.2}
\usepackage{amssymb,amsmath}
\usepackage[ruled,vlined]{algorithm2e}
\numberwithin{equation}{section}

\usepackage{unicode-math}
\defaultfontfeatures{Scale=MatchLowercase}
\defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}

% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\definecolor{default-linkcolor}{HTML}{A50000}
\definecolor{default-filecolor}{HTML}{A50000}
\definecolor{default-citecolor}{HTML}{4077C0}
\definecolor{default-urlcolor}{HTML}{4077C0}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdfauthor={Chuwen},
  hidelinks,
  breaklinks=true,
  pdfcreator={LaTeX via pandoc with the Eisvogel template}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=2.5cm,includehead=true,includefoot=true,centering,]{geometry}
% add backlinks to footnote references, cf. https://tex.stackexchange.com/questions/302266/make-footnote-clickable-both-ways
\usepackage{footnotebackref}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{3}

% Make use of float-package and set default placement for figures to H.
% The option H means 'PUT IT HERE' (as  opposed to the standard h option which means 'You may put it here if you like').
\usepackage{float}
\floatplacement{figure}{H}

\usepackage{booktabs}
\definecolor{tufeijilk}{RGB}{68,87,151}
\hypersetup{colorlinks=true,linkcolor=tufeijilk,urlcolor=cyan}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newenvironment{cslreferences}%
  {\setlength{\parindent}{0pt}%
  \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces}%
  {\par}

\author{Chuwen}
\date{\today}



%%
%% added
%%

%
% language specification
%
% If no language is specified, use English as the default main document language.
%

\usepackage{polyglossia}
\setmainlanguage[]{english}


%
% for the background color of the title page
%

%
% break urls
%
\PassOptionsToPackage{hyphens}{url}

%
% When using babel or polyglossia with biblatex, loading csquotes is recommended
% to ensure that quoted texts are typeset according to the rules of your main language.
%
\usepackage{csquotes}

%
% captions
%
\definecolor{caption-color}{HTML}{777777}
\usepackage[font={stretch=1.2}, textfont={color=caption-color}, position=top, skip=4mm, labelfont=bf, singlelinecheck=false, justification=raggedright]{caption}
\setcapindent{0em}

%
% blockquote
%
\definecolor{blockquote-border}{RGB}{221,221,221}
\definecolor{blockquote-text}{RGB}{119,119,119}
\usepackage{mdframed}
\newmdenv[rightline=false,bottomline=false,topline=false,linewidth=3pt,linecolor=blockquote-border,skipabove=\parskip]{customblockquote}
\renewenvironment{quote}{\begin{customblockquote}\list{}{\rightmargin=0em\leftmargin=0em}%
\item\relax\color{blockquote-text}\ignorespaces}{\unskip\unskip\endlist\end{customblockquote}}

%
% heading color
%
\definecolor{heading-color}{RGB}{40,40,40}
\addtokomafont{section}{\color{heading-color}}
% When using the classes report, scrreprt, book,
% scrbook or memoir, uncomment the following line.
%\addtokomafont{chapter}{\color{heading-color}}

%
% variables for title and author
%
\usepackage{titling}
\title{}
\author{Chuwen}

%
% tables
%

%
% remove paragraph indention
%
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines

%
%
% Listings
%
%


%
% header and footer
%
\usepackage{fancyhdr}

\fancypagestyle{eisvogel-header-footer}{
  \fancyhead{}
  \fancyfoot{}
  \lhead[\today]{}
  \chead[]{}
  \rhead[]{\today}
  \lfoot[\thepage]{Chuwen}
  \cfoot[]{}
  \rfoot[Chuwen]{\thepage}
  \renewcommand{\headrulewidth}{0.4pt}
  \renewcommand{\footrulewidth}{0.4pt}
}
\pagestyle{eisvogel-header-footer}

%%
%% end added
%%

\begin{document}

%%
%% begin titlepage
%%

%%
%% end titlepage
%%



{
\setcounter{tocdepth}{3}
\tableofcontents
}
\hypertarget{the-repair-model}{%
  \section{The repair model}\label{the-repair-model}}

\hypertarget{formulation}{%
  \subsection{Formulation}\label{formulation}}

\begin{quote}
  Notation
\end{quote}

\begin{itemize}
  \tightlist
  \item
        \(I, T\) - set of plane, time periods, respectively
  \item
        \(b, h\) - demand withdraw and plane idle cost, respectively
  \item
        \(\tau\) - lead time for maintenance
\end{itemize}

The demand is stochastic with some distribution \(f\in \mathscr F\)

\begin{itemize}
  \tightlist
  \item
        \(\mathbfit d_t\) - demand/number of planes needed at time \(t\)
\end{itemize}

\begin{quote}
  Decision
\end{quote}

\begin{itemize}
  \tightlist
  \item
        \(x_{it}\) - 0 - 1 variable, 1 if plane \(i\) starts a maintenance at
        time \(t\)
  \item
        \(u_{it}\) - 0 - 1 variable, 1 if plane is working at time \(t\)
  \item
        \(s_{it} \ge 0\) - the lifespan of plane \(i\) at time \(t\)
\end{itemize}

The DRO/SP model, the goal is to minimize unsatisfied demand and surplus
(idle) flights. A minimax objective function that is widely used in
Newsvendor problems can be written as follows:

\[\min_{u,x,s} b \cdot (d_t - \sum_i u_{it})_+ + h \cdot  ( \sum_i u_{it} - d_t)_+ \]

Alternatively, we use the following objective function with
\(\delta^+_t, \delta^-_t\) indicating unsatisfied demand and surplus,
respectively. Let \(z\) be the objective function

% \[\begin{align}
%     z =           & \min_{x_{it}, u_{it}, \delta_t^+, \delta_t^-} \sum_t (b\cdot  \delta_t^+ + h \cdot \delta_t^-)                                                       \\
%     \mathbf{s.t.} &                                                                                                                                                      \\
%                   & \sum_i u_{it} + \delta_t^+ - \delta_t^- = d_t                                                  & \forall t \in T                                     \\
%                   & s_{i, t+1} =  s_{i t}  - \alpha_i  u_{it} + \beta_i  x_{i, t- \tau}                            & \forall i \in I, t \in T                            \\
%                   & x_{it} +  u_{i, t} \le 1                                                                       & \forall i \in I, t \in T                            \\
%                   & x_{it} + x_{i\rho} + u_{i, \rho} \le 1                                                         & \forall i \in I,  t\in T, \rho = t + 1, ..., t+\tau \\
%                   & s_{i t} \ge L
%   \end{align}\]

\begin{equation}\label{eq_primal}
  \begin{aligned}
    z =           & \min_{x_{it}, u_{it}, \delta_t^+, \delta_t^-} \sum_t (b\cdot  \delta_t^+ + h \cdot \delta_t^-)                                                       \\
    \mathbf{s.t.} &                                                                                                                                                      \\
                  & \sum_i u_{it} + \delta_t^+ - \delta_t^- = d_t                                                  & \forall t \in T                                     \\
                  & s_{i, t+1} =  s_{i t}  - \alpha_i  u_{it} + \beta_i  x_{i, t- \tau}                            & \forall i \in I, t \in T                            \\
                  & x_{it} +  u_{i, t} \le 1                                                                       & \forall i \in I, t \in T                            \\
                  & x_{it} + x_{i\rho} + u_{i, \rho} \le 1                                                         & \forall i \in I,  t\in T, \rho = t + 1, ..., t+\tau \\
                  & s_{i t} \ge L                                                                                  & \forall i \in I, t \in T
  \end{aligned}
\end{equation}

We define the last four sets of constraint as \(\Omega_i\), which
describe the non-overlapping requirements during a maintenance for each
\(i\).

Let \(U, X, S \in \mathbb R^{|I|\times |T|}_+\) be the matrix of \(u_{it}, x_{it}\) and \(s_{it}\), \(U_{(i,.)}\) be the \(i\)th row of
\(U\). Let \(\delta^+, \delta^-\) be the vector of \(\delta_t^+, \delta_t^-\), respectively. It allows a more compact
formulation.
\begin{equation}\label{eq_pr_compact}
  \begin{aligned}
                  & \min_{U, X, S}  e^\top (b\cdot  \delta^+ + h \cdot \delta^-)                   \\
    \mathbf{s.t.} &                                                                                \\
                  & U^\top e + \delta^+ - \delta^- = d                           & \forall t \in T \\
                  & X_{(i,\cdot)}, U_{(i,\cdot)}, S_{(i,\cdot)} \in \Omega_i     & \forall i \in I
  \end{aligned}
\end{equation}

We propose a polynomial-time approximation to this problem by Lagrangian
relaxation and a subgradient method. At each iteration of the dual
search procedure, a set of sub-problems are solved by dynamic
programming. The convergence of any black-box subgradient method can be
found in (Polyak (1967), and books by Nesterov, Bertsimas, \ldots{} to
be added), and the complexity are verified on the level of
\(O(\frac{1}{\epsilon^2})\). We refer further analysis on the rate and
convergence of such class of algorithm to Nesterov (2009), Nedić and
Ozdaglar (2009). Since regular sugradient method does not grant primal
feasibility, there are methods\ldots{} We use the volume algorithm
described in Barahona and Anbil (2000) to update the dual multipliers
while approximating a primal feasible solutions to the linear
relaxation. The volume algorithm applied to our problem has further
properties. Besides the lower bound acquired in the dual relaxation, the
convex combination of past iterations in the algorithm gives an upper
bound to the original problem. This explicitly bounds the optimal value.
Although the solution terminated at the subgradient method is not
guaranteed to be integral, it gives a tight interval that asymptotically
approaches to the optimal value.

If we allow a tolerance \(\epsilon \ge 0\) on subgradient method, the
worst overall complexity is
\(O\left(\frac{1}{\epsilon^2}\cdot\tau\cdot|I|\cdot|T|^3\right)\).

\hypertarget{lagrangian-relaxation}{%
  \subsection{Lagrangian Relaxation}\label{lagrangian-relaxation}}

\begin{verbatim}
todo
- can do better on complexity
\end{verbatim}

The Lagrangian is introduced by relaxing the equality constraint, so we
have:

\[\begin{aligned}
    z_{\mathsf{LD}} & = - \sum_t \lambda_t d_t + \min_{\delta_t^+, \delta_t^-, U} \sum_t \left [ (b + \lambda_t) \cdot \delta_t^+ + (h-\lambda_t)\cdot \delta_t^- \right ] + \sum_i \sum_t\lambda_t u_{it} \\
  \end{aligned}\]

\(z_{\mathsf{LD}}(\lambda)\) is unbounded unless
\(-b \le \lambda_t \le h\), it reduces to a set of low dimensional
minimization problems for each \(i\):

\[\begin{aligned}
    z_{\mathsf{LD}} & = - \sum_t \lambda_t d_t  + \min_{U}\sum_i \sum_t\lambda_t u_{it} \\
    \mathbf {s.t. } &                                                                   \\
                    & X_{(i,\cdot)}, U_{(i,\cdot)}, S_{(i,\cdot)} \in \Omega_i          \\
                    & -b \le \lambda_t \le h
  \end{aligned}\]

Next we provide analysis on properties of the subproblem.

\hypertarget{subproblem-for-each-plane}{%
  \subsubsection{Subproblem for each
    plane}\label{subproblem-for-each-plane}}

In the dual search process, one should solve a set of subproblems
\(\forall i\in I\) defined as follows:

\[\begin{aligned}
    \min_{\Omega_i} \sum_t \lambda_t \cdot u_{i,t}
  \end{aligned}\]

The model describes a problem to minimize total cost while keeping the
lifespan safely away from the lower bound \(L\). We sol‘ve this by
dynamic programming.

Define state: \(y_t = \left[m_t,s_t \right]^\top\), where \(m_t\)
\textbf{denotes the remaining time of the undergoing maintenance}.
\(s_t\) is the remaining lifespan. At each period \(t\) we decide
whether the plane \(i\) is idle or waiting (for the maintenance),
working, or starting a maintenance, i.e.:

\[(u_t, x_t) \in \left\{(1, 0), (0,0), (0, 1)\right\}\]

We have the Bellman equation:
\[V_n(u_t, x_t | m_t, s_t) = \lambda_t \cdot u_t + \min_{u,x} V_{n-1}(...)\]

Complexity: let \(s_0\) be the initial lifespan and finite time horizon
be \(|T|\), we notice the states for remaining maintenance waiting time
is finite, \(m_t \in \{0, 1, ..., \tau\}\).

Let total number of possible periods to initiate a maintenance be
\(n_1\), and working periods be \(n_2\). If we ignore lower bound \(L\)
on \(s\), total number of possible values of \(s\) is bounded above:
\(|s| = \sum_i^{|T|}\sum_j^{|T| - i} 1=(|T| + 1)(\frac{1}{2}|T| + 1)\)
since \(n_1 + n_2 \le |T|\). For each subproblem we have at most 3
actions, thus we conclude this problem can be solved by dynamic
programming in polynomial time, the complexity is:
\(O\left(\tau\cdot|T|^3 \right)\)

\hypertarget{subgradient-method}{%
  \subsubsection{Subgradient Method}\label{subgradient-method}}

Lagrange multipliers is updated by the subgradient method, ·
The parameter \(\alpha\) to produce convex combinations of history solutions is updated by the procedure in ... to approach better precision.


\begin{algorithm}[H]
  \SetAlgoLined
  initialize multipliers \(\bar \lambda = e\), stepsize \(s^0\), solve \(z_\mathsf{LD}(\bar \lambda) \)
  to obtain primal solution \((\bar X, \bar U, \bar S) \)  \;
  \While{\(||\nabla^k_\lambda|| \le \epsilon_\nabla\) and \(z\)  }{
    compute subgradient \(\nabla^k_\lambda = \bar U^\top e - d \),
    let \(\lambda^k = \bar \lambda + s^k \cdot \nabla^k_\lambda\),
    where stepsize \(s^k\) is computed from ..., \;
    solve \(z_\mathsf{LD}^k = z_\mathsf{LD}(\lambda^k) \)
    to obtain primal solution \((X^k, U^k, S^k)\)\;
    update primal solution \(\bar U, \bar X, \bar S\) by the same routine,
    \(\bar X\) for example.
    \[\bar X = (1 - \alpha) \bar X  + \alpha X^k \]

    \If{\(z_\mathsf{LD}^k > \bar z_\mathsf{LD} \)}{
      update:
      \(\bar \lambda \leftarrow \lambda^k\),
      \(\bar z \leftarrow z^k\)
    }
    recover solution to primal problem by \ref{eq_pr_compact}:

    set iteration number \(k \leftarrow k + 1\)
  }
  \caption{The Volume Algorithm}
\end{algorithm}

Notice:

\begin{itemize}
  \item
        At iteration \(k\), suppose
        \(-b \le \lambda^k_t \le h, \forall t \in T\), we use dynamic
        programming to solve the relaxed minimization problem, then the
        (integral) solution \(( X^k, S^k, U^k)\) is also feasible for the
        original problem (compute \(\delta^+, \delta^-\) accordingly). The
        primal value \(z^k\) is the upper bound for optimal solution
        \(z^\star\): \(z^k\ge z^\star\).
  \item
        In the volume algorithm, we consider the convex combination \(\bar X\)
        of past iterations \(\{X^1, ..., X^k\}\). We update
        \(\bar X \leftarrow \alpha X^k + (1-\alpha) \bar X\). It's easy to
        verify \(\bar z \ge z^\star \ge z_{\textsf{LD}}^k\), where \(\bar z\)
        is the primal objective value for \(\bar X\) and \(z_{\textsf{LD}}^k\)
        is the dual value for \(X^k\). By the termination criterion
        \(|\bar z - z_{\textsf{LD}}^k| \le \epsilon_z\) for some small value
        \(\epsilon_z >0\), we conclude the \(\bar z\) converges to the optimal
        value \(z^\star\).
  \item
        While \(\bar z \to z^\star\), there is no guarantee for the solution
        \(\bar X, \bar U\) being integral via the volume algorithm;
        \(\bar X, \bar U\) is feasible only to the linear relaxation.
  \item
        Remark:

        \begin{itemize}
          \tightlist
          \item
                The projection for dual variables is simple since there is only a
                box constraint. More computation would be needed if we use the
                minimax objective function, i.e.,
                \(q \ge h\cdot (U^\top e - d), q\ge b\cdot (d-U^\top e)\), in which
                case two set of multipliers are needed, say \(\lambda, \mu \ge 0\),
                and the projection should be done onto:
                \[\{(\lambda,\mu)|\lambda +\mu \le 1\}\]
        \end{itemize}
\end{itemize}

\hypertarget{rounding}{%
  \subsubsection{Rounding}\label{rounding}}

\begin{itemize}
  \tightlist
  \item
        *compute \(\min c ^\top | x - x^\star|\) where \(x^\star\) is the
        (possibly) fractional solution achieving the best bound, using DP.
\end{itemize}

still working on this.

\hypertarget{numerical-experiments}{%
  \subsubsection{Numerical Experiments}\label{numerical-experiments}}

In this section, In this section, we report numerical results to
demonstrate the efficiency and effectiveness of our proposed algorithms
for solving the repair problem (\textbf{ref here}). We parallelize the
subproblems to available cores solved by dynamic programming.

(details on the algorithm, parameters, et cetera.)

\hypertarget{convergence-of-lagrange-relaxation}{%
  \paragraph{Convergence of Lagrange
    Relaxation}\label{convergence-of-lagrange-relaxation}}

We randomly generated 5-8 instances for each problem class with size
\(|I| = 10, 15, 20\) and \(|T| = 25, 30\). We use Gurobi 9.1 to compute
benchmarks: lower bound \(\mathsf{bench\_lb}\) and primal objective
value \(\mathsf{bench\_sol}\) within 300 seconds. The value and bound
for subgradient methods are \(\mathsf{subgrad\_val}\),
\(\mathsf{subgrad\_lb}\), respectively. We set the maximum iterations to
400 so that the subgradient method terminates at a comparable time with
Gurobi. At last, we compare \(\mathsf{primal\_gap}\) and
\(\mathsf{bound\_gap}\) in the last two columns. All the computations
have been performed on a Mac mini (2018) with 3.2 GHz 6-Core Intel Core
i7 processor and a RAM of 32 GB.

It can be observed that the subgradient method performed closely to
commercial mixed-integer linear solver.

\begin{table}
  \caption{Computational results on convergence to optimal solution $z^\star$} \label{tab:sgsconv}
  \begin{tabular}{|l|l|r|r|r|r|l|l|}
    \toprule
    $|I|$ & $|T|$ & $\mathsf{bench\_lb}$ & $\mathsf{bench\_sol}$ & $\mathsf {subgrad\_val}$ & $\mathsf{subgrad\_lb}$ & $\mathsf{primal\_gap}$ & $\mathsf{bound\_gap}$ \\
    \midrule
    15    & 25    & 50.545103            & 52.000000             & 51.567854                & 50.593575              & -0.83\%                & 0.10\%                \\
    20    & 25    & 58.583531            & 76.000000             & 70.658525                & 69.975157              & -7.03\%                & 19.45\%               \\
    20    & 25    & 144.000000           & 144.000000            & 144.715790               & 143.375955             & 0.50\%                 & -0.43\%               \\
    10    & 30    & 50.160760            & 52.000000             & 52.366787                & 52.000000              & 0.71\%                 & 3.67\%                \\
    10    & 30    & 50.000000            & 50.000000             & 50.394692                & 50.000000              & 0.79\%                 & 0.00\%                \\
    15    & 25    & 88.000000            & 88.000000             & 88.725505                & 88.000000              & 0.82\%                 & 0.00\%                \\
    10    & 25    & 49.999998            & 49.999998             & 50.420987                & 50.000000              & 0.84\%                 & 0.00\%                \\
    10    & 25    & 48.968605            & 50.000000             & 50.422554                & 50.000000              & 0.85\%                 & 2.11\%                \\
    10    & 30    & 81.999998            & 82.000000             & 82.718656                & 81.938236              & 0.88\%                 & -0.08\%               \\
    20    & 25    & 52.198486            & 53.999995             & 54.480932                & 53.974198              & 0.89\%                 & 3.40\%                \\
    20    & 25    & 146.000000           & 146.000000            & 147.319376               & 145.898549             & 0.90\%                 & -0.07\%               \\
    20    & 25    & 118.000000           & 118.000000            & 119.063879               & 118.000000             & 0.90\%                 & 0.00\%                \\
    15    & 25    & 88.000000            & 88.000000             & 88.788297                & 88.000000              & 0.90\%                 & 0.00\%                \\
    10    & 30    & 28.507084            & 30.000000             & 30.268855                & 30.000000              & 0.90\%                 & 5.24\%                \\
    20    & 25    & 136.236668           & 138.000000            & 139.251805               & 137.915722             & 0.91\%                 & 1.23\%                \\
    10    & 30    & 86.655991            & 88.000000             & 88.818326                & 88.000000              & 0.93\%                 & 1.55\%                \\
    10    & 30    & 60.000000            & 60.000000             & 60.565028                & 60.000000              & 0.94\%                 & 0.00\%                \\
    10    & 25    & 72.000000            & 72.000000             & 72.698958                & 72.000000              & 0.97\%                 & 0.00\%                \\
    15    & 25    & 84.000000            & 84.000000             & 84.837668                & 84.000000              & 1.00\%                 & 0.00\%                \\
    10    & 30    & 44.775258            & 50.000000             & 50.583272                & 49.454663              & 1.17\%                 & 10.45\%               \\
    10    & 25    & 40.000000            & 40.000000             & 40.766048                & 39.747977              & 1.92\%                 & -0.63\%               \\
    10    & 30    & 33.175978            & 35.999999             & 36.747449                & 34.966511              & 2.08\%                 & 5.40\%                \\
    10    & 25    & 9.386239             & 14.000000             & 14.342575                & 14.000000              & 2.45\%                 & 49.15\%               \\
    15    & 25    & 34.000000            & 34.000000             & 35.802835                & 34.000000              & 5.30\%                 & 0.00\%                \\
    \bottomrule
  \end{tabular}
  \small
\end{table}

\hypertarget{reference}{%
  \section*{Reference}\label{reference}}
\addcontentsline{toc}{section}{Reference}

\hypertarget{refs}{}
\begin{cslreferences}
  \leavevmode\hypertarget{ref-barahona_volume_2000}{}%
  Barahona F, Anbil R (2000) The volume algorithm: Producing primal
  solutions with a subgradient method. \emph{Mathematical Programming}
  87(3):385--399.

  \leavevmode\hypertarget{ref-nedic_approximate_2009}{}%
  Nedić A, Ozdaglar A (2009) Approximate primal solutions and rate
  analysis for dual subgradient methods. \emph{SIAM Journal on
    Optimization} 19(4):1757--1780.

  \leavevmode\hypertarget{ref-nesterov_primal-dual_2009}{}%
  Nesterov Y (2009) Primal-dual subgradient methods for convex problems.
  \emph{Mathematical programming} 120(1):221--259.

  \leavevmode\hypertarget{ref-polyak_general_nodate}{}%
  Polyak BT (1967) A general method for solving extremal problems.
  \emph{Soviet Mathematics Doklady}:5.
\end{cslreferences}

\end{document}
